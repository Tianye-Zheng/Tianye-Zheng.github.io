---
layout: post
title:  "数据挖掘导论(2)-认识数据"
date:   2019-02-25
desc: ""
keywords: "大数据"
categories: [大数据]
tags: [大数据]
icon: icon-html
---


<br />
# Chap 2 Getting to Know Your Data
<br />


**数据对象** : A data object represents an entity. Data objects can also be referred to as samples, examples, instances, data points, or objects. If the data objects are stored in a database, they are data tuples.

**属性** : An attribute is a data field, representing a characteristic or feature of a data object. The nouns attribute, dimension, feature, and variable are often used interchangeably.

observed values (观测值) for a given attribute are known as observations (观测)

A set of attributes used to describe a given object is called an attribute vector (or feature vector)

<br />
### 标称属性 (normal attributes)

Nominal means “relating to names.” The values of a nominal attribute are symbols or names of things. Each value represents some kind of category, code, or state, and so nominal attributes are also referred to as categorical (分类的). The values do not have any meaningful order (序). In computer science, the values are also known as enumerations (枚举的).

<br />
### 二元属性 (binary attributes)

A binary attribute is a nominal attribute with only two categories or states: 0 or 1

<br />
### 序数属性 (ordinal attributes)

An ordinal attribute is an attribute with possible values that have a meaningful order or ranking among them, but the magnitude between successive values is not known.

<br />
### 数值属性 (numeric attributes)

A numeric attribute is quantitative; that is, it is a measurable quantity, represented in integer or real values. Numeric attributes can be interval-scaled (区间标度, measured on a scale of equal-size units) or ratio-scaled (比率标度, with an inherent zero-point).

<br />
### 离散属性与连续属性 (Discrete versus Continuous Attributes)

A discrete attribute has a ﬁnite or countably inﬁnite set of values. If an attribute is not discrete, it is continuous.

<br />
## 数据的基本统计描述
<br />

### 中心趋势度量：均值、中位数和众数
<br />

**中列数** (midrange): It is the average of the largest and smallest values in the set.

### 度量数据散布：极差、四分位数、方差、标准差和四分位数极差
<br />

**极差**（range）：The range of the set is the difference between the largest (max()) and smallest (min()) values.

**分位数**：Quantiles are points taken at regular intervals of a data distribution, dividing it into essentially equalsize consecutive sets.

**四分位数极差** 

$$IRQ=Q_{3}-Q_{1}$$

$$Q_{1}$$ is the first quartile, $$Q_{3}$$ is the third quartile

**五数概括** (five number summary) : consists of the median ($$Q_{2}$$), the quartiles $$Q_{1}$$ and $$Q_{3}$$, and the smallest and largest individual observations, written in the order of Minimum, $$Q_{1}$$, Median, $$Q_{3}$$, Maximum

**盒图** (boxplot) : popular way of visualizing a distribution. A boxplot incorporates the ﬁve-number summary as follows:

+ Typically, the ends of the box are at the quartiles so that the box length is the interquartile range.
+ The median is marked by a line within the box.
+ Two lines (called whiskers) outside the box extend to the smallest (Minimum) and largest (Maximum) observations.

<img src="https://raw.githubusercontent.com/Tianye-Zheng/Tianye-Zheng.github.io/master/PostPictures/2019-02-25/1.png" width = "300" height =
"300"/>

### 度量数据的相似性和相异性
<br />

A **cluster**（簇）is a collection of data objects such that the objects within a cluster are similar to one another and dissimilar to the objects in other clusters.

**数据矩阵 Data matrix** (or object-by-attribute structure): This structure stores the n data objects in the form of a relational table, or n-by-p matrix (n objects ×p attributes):

<img src="https://raw.githubusercontent.com/Tianye-Zheng/Tianye-Zheng.github.io/master/PostPictures/2019-02-25/2.png" width = "200" height =
"150"/>

**相异性矩阵 Dissimilarity matrix** (or object-by-object structure): This structure stores a collection of proximities that are available for all pairs of n objects. It is often represented by an n-by-n table, 

where d(i, j) is the measured dissimilarity or “difference” between objects i and j.

<img src="https://raw.githubusercontent.com/Tianye-Zheng/Tianye-Zheng.github.io/master/PostPictures/2019-02-25/3.png" width = "250" height =
"150"/>

Measures of **similarity 相似性** can often be expressed as a function of measures of dissimilarity. For example, for nominal data,

$$sim(i,j)=1-d(i,j)$$

<br />
### 标称属性的邻近性度量

The dissimilarity between two objects i and j can be computed based on the ratio of mismatches:

$$d(i,j)=\frac{p-m}{m}$$

where m is the number of matches(i.e.,the number of attributes for which i and j are in the same state)

Alternatively, similarity can be computed as

$$sim(i,j)=1-d(i,j)=\frac{m}{p}$$

<br />
### 二元属性的邻近性度量

<img src="https://raw.githubusercontent.com/Tianye-Zheng/Tianye-Zheng.github.io/master/PostPictures/2019-02-25/4.png" width = "300" height =
"150"/>

where q is the number of attributes that equal 1 for both objects i and j,...

dissimilarity between i and j is

$$d(i,j)=\frac{r+s}{q+r+s+t}$$

For asymmetric binary attributes, the two states are not equally important。 The dissimilarity based on these attributes is called **asymmetric binary dissimilarity ( 非对称的二元相异性 )**, where the number of negative matches, t, is considered unimportant and is thus ignored in the following computation:

$$d(i,j)=\frac{r+s}{q+r+s}$$

**asymmetric binary similarity ( 非对称的二元相似性 )** 
 
$$sim(i,j)=\frac{q}{q+r+s}=1-d(i,j)$$

$$sim(i,j)$$ is called the **Jaccard coefficient ( Jaccard系数 )**

<br />
### 数值属性的相异性：闵可夫斯基距离

Let $$i = (x_{i1} , x_{i2} ,..., x_{ip} )$$ and $$j = (x_{j1} , x_{j2} ,..., x_{jp} )$$ be two objects described by p numeric attributes.

**Euclidean distance 欧几里得距离**

$$d(i,j)=\sqrt{(x_{i1}-x_{j1})^{2}+(x_{i2}-x_{j2})^{2}+...+(x_{ip}-x_{jp})^{2}}$$

**Manhattan (or city block) distance 曼哈顿距离**

$$d(i,j)=\mid x_{i1}-x_{j1}\mid +\mid x_{i2}-x_{j2}\mid +...+\mid x_{ip}-x_{jp}\mid$$

Both the Euclidean and the Manhattan distance satisfy the following mathematical properties:

+ **Non-negativity 非负性** : $$d(i,j)\geq 0$$ distance is a non-negative number
+ **Identity of indiscernibles 同一性** : $$d(i,i)=0$$ the distance of an object to itself is 0
+ **Symmetry 对称性** : $$d(i,j)=d(j,i)$$
+ **Triangle inequality 三角不等式** : $$d(i,j) \leq d(i,k)+d(k,j)$$

A measure that satisﬁes these conditions is known as **metric 度量**. 

*Note that the non-negativity property is implied by the other three properties.*

**Minkowski distance 闵可夫斯基距离** is a generalization of the Euclidean and Manhattan distances. It is deﬁned as

$$d(i,j)=\sqrt[h]{(x_{i1}-x_{j1})^{h}+(x_{i2}-x_{j2})^{h}+...+(x_{ip}-x_{jp})^{h}}$$

where h is a real number such that $$h \geq 1$$.

also called **$$L_{p}$$ norm 范数**, where the symbol p refers to our notation of h. It represents the Manhattan distance when h=1 ( i.e., $$L_{1} norm$$ ) and Euclidean distance when h=2 ( i.e., $$L_{2} norm$$ )

The **supremum distance 上确界距离** ( also referred to as $$L_{max}$$ , $$L_{\infty} norm$$ and as the **Chebyshev distance 切比雪夫距离** ) is a generalization of the Minkowski distance for $$h\to \infty$$.

to compute it, we find the attribute f that gives the maximum difference in values between the two objects, this difference is the supremum distance, defined more formally as:

$$d(i,j)=lim_{h\to \infty}(\sum_{f=1}^{p}\mid x_{if}-x_{jf}\mid ^{h})^{\frac{1}{h}}=max_{f}^{p}\mid x_{if}-x_{jf}\mid$$

the $$L_{\infty} norm$$ is also known as the **uniform norm 一致范数**

**weighted Euclidean distance 加权欧几里得距离**

$$d(i,j)=\sqrt{w_{1}(x_{i1}-x_{j1})^{2}+w_{2}(x_{i2}-x_{j2})^{2}+...+w_{m}(x_{ip}-x_{jp})^{2}}$$

<br />
### 序数属性的临近性度量

1. The value of f for the ith object is $$x_{if}$$ , and f has $$M_{f}$$ ordered states, representing the ranking 1,..., $$M_{f}$$ . Replace each x if by its corresponding rank, $$r_{if}\in {1,...,M_{f}}$$.
2. Since each ordinal attribute can have a different number of states, it is often necessary to map the range of each attribute onto [0.0, 1.0] so that each attribute has equal weight. We perform such data normalization by replacing the rank $$r_{if}$$ of the ith object in the fth attribute by **$$z_{if}=\frac{r_{if}-1}{M_{f}-1}$$**
3. Dissimilarity can then be computed using any of the distance measures for numeric attributes, using $$z_{if}$$ to represent the f value for the ith object.

Similarity values for ordinal attributes can be interpreted from dissimilarity as $$sim(i,j) = 1 − d(i,j).$$

<br />
### 混合类型属性的相异性

Suppose that the data set contains p attributes of mixed type. The dissimilarity d(i, j) between objects i and j is deﬁned as

$$d(i,j)=\frac{\sum_{f=1}^{p}\delta^{(f)}_{ij}d_{ij}^{(f)}}{\sum_{f=1}^{p}\delta^{(f)}_{ij}}$$

where the indicator $$\delta^{(f)}_{ij}=0$$ if either $$x_{if}$$ or $$x_{jf}$$ is missing , or $$x_{if}=x_{jf}=0$$ and attribute f is asymmetric binary; otherwise, $$\delta^{(f)}_{ij}=1$$

$$d_{ij}^{(f)}$$ is computed dependent on its type, the steps are identical to what we have seen, The only difference is for numeric attributes, where we normalize so that the values map to the interval [0.0, 1.0].

<br />
### 余弦相似性

Let x and y be two vectors for comparison. Using the cosine measure as a similarity function, we have

$$sim(x,y)=\frac{x\cdot y}{\mid\mid x \mid\mid \mid\mid y \mid\mid}$$

where $$\mid\mid x \mid\mid$$ is the Euclidean norm of vector $$x=(x_{1},x_{2},...,x_{p})$$, defined as $$\sqrt{x_{1}^{2}+x_{2}^{2}+...+x_{p}^{2}}$$ , conceptually, it is the length of the vector.

*Note that cosine similarity is referred to as a nonmetric measure 非度量测度*