---
layout: post
title:  "数据挖掘导论(3)—数据预处理"
date:   2019-02-26
desc: ""
keywords: "大数据"
categories: [大数据]
tags: [大数据]
icon: icon-html
---


<br />
# Chap 3 Data Preprocessing
<br />

<br />
## 数据预处理：概述

`Data cleaning 数据清理` routines work to “clean” the data by filling in missing values, smoothing noisy data, identifying or removing outliers, and resolving inconsistencies.

`Data reduction 数据归约` obtains a reduced representation of the data set that is much smaller in volume, yet produces the same (or almost the same) analytical results. Data reduction strategies include dimensionality reduction 维归约 and numerosity reduction 数值归约.

Normalization, data discretization, and concept hierarchy generation are forms of `data transformation 数据变换`.

`Noise 噪声` is a random error or variance 随机误差或方差 in a measured variable.

<br />
### 数据光滑技术

`binning 分箱` : binning methods smooth a sorted data value by consulting its " neighborhood ", that is, the values around it.

The sorted values are distributed into a number of “buckets,” or bins.

Because binning methods consult the neighborhood of values, they perform local smoothing 局部光滑.

smoothing by bin means 用箱均值光滑

smoothing by bin medians 用箱中位数光滑

smoothing by bin boundaries 用箱边界光滑

<img src="https://raw.githubusercontent.com/Tianye-Zheng/Tianye-Zheng.github.io/master/PostPictures/2019-02-25/5.png" width = "350" height =
"320"/>

`Regression 回归` : Data smoothing can also be done by regression, a technique that conforms data values to a function.

`Outlier analysis 离群点分析` : Outliers may be detected by clustering, for example, where similar values are organized into groups, or “clusters.” Intuitively, values that fall outside of the set of clusters may be considered outliers.

<br />
### 数据集成

`entity identification problem 实体识别问题` how can equivalent real-world entities from multiple data sources be matched up.

`redundancy 冗余` is another important issue in data integration. an attribute may be redundant if it can be " derived " from another attribute or set of attributes. Inconsistencies in attribute or dimension naming can also cause redundancies in the resulting data set.

Some redundancies can be detected by `correlation analysis 相关分析`.

<br />
#### 标称数据的 $$\chi^{2}$$ 检验

The data tuples described by A and B can be shown as a `contingency table 相依表`, with the c values of A making up the columns and the r values of B making up the rows.

Suppose attribute A has $$c$$ distinct values, namely $$a_{1},a_{2},...,a_{c}$$. Attribute B has $$r$$ distinct values, namely $$b_{1},b_{2},...,b_{r}$$ .

Let $$(A_{i},B_{j})$$ denote the joint event that attribute A takes on value $$a_{i}$$ and attribute B takes on value $$b_{j}$$, that is, where $$(A = a_{i}, B = b_{j})$$. Each and every possible $$(A_{i},B_{j})$$ joint event has its own cell (or slot) in the table.

The $$\chi^{2}$$ value is computed as

$$\chi^{2} = \sum_{i=1}^{c}\sum_{j=1}^{r}\frac{(o_{ij}-e_{ij})^{2}}{e_{ij}}$$

where $$o_{ij}$$ is the `observed frequency (i.e., actual count) 观测频度，即实际计数` 

$$e_{ij}$$ is the `expected frequency 期望频度` of $$(A_{i},B_{j})$$

$$e_{ij} = \frac{count(A=a_{i})\times count(B=b_{j})}{n}$$

where n is the number of data tuples, $$count(A=a_{i})$$ is the number of tuples having value $$a_{i}$$ of A, and $$count(B=b_{i})$$ is the number of tuples having value $$b_{i}$$ of B

*Note that the cells that contribute the most to the $$\chi^{2}$$ value are those for which the actual count is very different from that expected.*

<br />
#### 数值数据的相关系数

evaluate the correlation between two attributes, A and B, by computing the `correlation coefficient 相关系数`

$$r_{A,B} = \frac{\sum_{i=1}^{n}(a_{i}-\overline{A})(b_{i}-\overline{B})}{n\sigma_{A}\sigma_{B}} = \frac{\sum_{i=1}^{n}(a_{i}b_{i})-n\overline{A}\overline{B}}{n\sigma_{A}\sigma_{B}}$$

$$\sigma_{A}$$ and $$\sigma_{B}$$ are the respective `standard deviations 标准差` of A and B 

Note that $$-1\leq r_{A,B}\leq 1$$. If $$r_{A,B}$$ is greater than 0, then A and B are positively correlated, meaning that the values of A increase as the values of B increase. The higher the value, the stronger the correlation. Hence, a higher value may indicate that A (or B) may be removed as a redundancy.

<br />
#### 数值数据的协方差

Consider two numeric attributes A and B, and a set of n observations $$\{(a_{1},b_{1}),...,(a_{n},b_{n})\}$$ 

The mean values of A and B, respectively, are also known as the `expected values 期望值` on A and B, that is,

$$E(A)=\overline{A}=\frac{\sum_{i=1}^{n}a_{i}}{n}\quad E(B)=\overline{B}=\frac{\sum_{i=1}^{n}b_{i}}{n}$$

The `covariance 协方差` between A and B is deﬁned as

$$Cov(A,B)=E((A-\overline{A})(B-\overline{B}))=\frac{\sum^{n}_{i=1}(a_{i}-\overline{A})(b_{i}-\overline{B})}{n}$$

$$r_{A,B}=\frac{Cov(A,B)}{\sigma_{A}\sigma_{B}}$$

$$Cov(A,B) = E(A\cdot B)-\overline{A}\overline{B}$$

If A and B are independent, the covariance is 0, however, the converse is not true.

<br />
### 数据归约

`Data reduction` techniques can be applied to obtain a reduced representation of the data set that is much smaller in volume, yet closely maintains the integrity of the original data.

`Dimensionality reduction 维归约` is the process of reducing the number of random variables or attributes under consideration.

`Numerosity reduction 数量归约` techniques replace the original data volume by alternative, smaller forms of data representation.

`Data compression 数据压缩` transformations are applied so as to obtain a reduced or “compressed” representation of the original data.

<br />
#### 小波变换


<br />
#### 主成分分析

<br />
#### 属性子集选择

<br />
#### 回归和对数线性模型：参数化归约数据